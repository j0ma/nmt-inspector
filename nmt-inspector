#!/usr/bin/env python

import json
import os
import random
from itertools import zip_longest
from pathlib import Path

import click
from rich.console import Console
from rich.table import Table

# Total screen width
TOTAL_WIDTH = 120


def grab_from_env(var_name, default=None):
    return os.environ.get(var_name, default)


@click.group()
def cli():
    pass


def get_data(source, reference, hypothesis):
    source_path = Path(source)
    reference_path = Path(reference)
    hypothesis_path = Path(hypothesis)

    with open(source_path, "r") as f:
        source_data = f.read().splitlines()
    with open(reference_path, "r") as f:
        reference_data = f.read().splitlines()
    with open(hypothesis_path, "r") as f:
        hypothesis_data = f.read().splitlines()

    combined_data = list(zip(source_data, reference_data, hypothesis_data))

    return combined_data


def get_data_json(json_file, json_source_key, json_reference_key, json_hypothesis_key):
    json_lines = [json.loads(line) for line in click.open_file(json_file)]

    source_data = [data[json_source_key] for data in json_lines]
    reference_data = [data[json_reference_key] for data in json_lines]
    hypothesis_data = [data[json_hypothesis_key] for data in json_lines]

    combined_data = list(zip(source_data, reference_data, hypothesis_data))

    return combined_data


def get_data_multi_hyp(source, reference, hypothesis_files):
    source_path = Path(source)
    reference_path = Path(reference)
    hypothesis_paths = [Path(h) for h in hypothesis_files]

    hypothesis_data = []
    with open(source_path, "r") as f:
        source_data = f.read().splitlines()
    with open(reference_path, "r") as f:
        reference_data = f.read().splitlines()

    for hyp_file in hypothesis_paths:
        with open(hyp_file, "r") as f:
            hypothesis_data.append(f.read().splitlines())

    # Transpose the hypothesis data
    hypothesis_data = list(zip(*hypothesis_data))

    combined_data = list(zip(source_data, reference_data, hypothesis_data))

    return combined_data


@cli.command()
@click.option("--nsamp", "-n", help="The number of samples to print.")
@click.option("--source", "-src", type=click.Path(exists=True), help="The source file.")
@click.option(
    "--reference", "-ref", type=click.Path(exists=True), help="The reference file."
)
@click.option(
    "--hypothesis", "-hyp", type=click.Path(exists=True), help="The hypothesis file."
)
@click.option("--json-mode", is_flag=True)
@click.option("--json-file", type=click.Path(exists=True))
@click.option("--json-source-key", default="source")
@click.option("--json-reference-key", default="reference")
@click.option("--json-hypothesis-key", default="hypothesis")
def inspect_translations(
    nsamp,
    source,
    reference,
    hypothesis,
    json_mode,
    json_file,
    json_source_key,
    json_reference_key,
    json_hypothesis_key,
):
    # Grab nsamp from environment if not provided
    nsamp = int(nsamp) if nsamp else int(grab_from_env("NSAMP", 10))

    if json_mode:
        combined_data = get_data_json(
            json_file, json_source_key, json_reference_key, json_hypothesis_key
        )
    else:
        combined_data = get_data(source, reference, hypothesis)
    original_indices = list(range(len(combined_data)))
    shuffled_indices = list(range(len(combined_data)))
    random.shuffle(shuffled_indices)

    old_to_new_index_map = dict(zip(original_indices, shuffled_indices))

    console = Console()

    for i, _ in enumerate(combined_data[:nsamp], start=1):
        real_index = old_to_new_index_map[i]
        src, ref, hyp = combined_data[real_index]

        table = Table(show_header=True, header_style="bold magenta", padding=(0, 1))
        table.add_column("Example", style="dim", width=12)
        table.add_column("Text", width=100)

        table.add_row("Source", src)
        table.add_row("Reference", ref)
        table.add_row("Hypothesis", hyp)

        console.print(f"Example {i} (real: {real_index}):")
        console.print(table)
        console.print("\n")


@cli.command()
@click.option(
    "--index",
    "-i",
    help="The index of the sentence to inspect.",
    type=int,
    required=True,
)
@click.option("--source", "-src", type=click.Path(exists=True), help="The source file.")
@click.option(
    "--reference", "-ref", type=click.Path(exists=True), help="The reference file."
)
@click.option(
    "--hypothesis", "-hyp", type=click.Path(exists=True), help="The hypothesis file."
)
def inspect_sentence(index, source, reference, hypothesis):
    combined_data = get_data(source, reference, hypothesis)

    src, ref, hyp = combined_data[index]

    console = Console()
    table = Table(show_header=True, header_style="bold magenta", padding=(0, 1))

    # Add columns to display one token per row
    table.add_column("Example", style="dim", width=12)
    table.add_column("Source", width=33)
    table.add_column("Reference", width=33)
    table.add_column("Hypothesis", width=33)

    for token_idx, (s, r, h) in enumerate(
        zip_longest(src.split(), ref.split(), hyp.split())
    ):
        table.add_row(f"Token {token_idx}", s, r, h)

    console.print(table)


@cli.command()
@click.option(
    "--index",
    "-i",
    help="The index of the sentence to inspect.",
    type=int,
    required=True,
)
@click.option("--source", "-src", type=click.Path(exists=True), help="The source file.")
@click.option(
    "--reference", "-ref", type=click.Path(exists=True), help="The reference file."
)
@click.argument("hypothesis_files", nargs=-1)
def compare(index, source, reference, hypothesis_files):
    combined_data = get_data_multi_hyp(source, reference, hypothesis_files)

    src, ref, hyps = combined_data[index]
    row_of_strings = [src, ref] + list(hyps)
    row_of_token_lists = [s.split() for s in row_of_strings]

    # How many columns
    n_columns = 2 + len(hypothesis_files)
    sentence_col_width = TOTAL_WIDTH // n_columns

    console = Console()
    table = Table(show_header=True, header_style="bold magenta", padding=(0, 1))

    # Add columns to display one token per row
    table.add_column("Example", style="dim", width=12)
    table.add_column("Source", width=sentence_col_width)
    table.add_column("Reference", width=sentence_col_width)

    for idx, hypfile in enumerate(hypothesis_files, start=1):
        hypfile_path = Path(hypfile)
        table.add_column(f"H{idx}: {hypfile_path.name}", width=sentence_col_width)

    # Iterate over tokens in the source, reference, and hypotheses

    for token_idx, tokens in enumerate(zip_longest(*row_of_token_lists, fillvalue="")):
        table.add_row(f"Token {token_idx}", *tokens)

    console.print(table)


if __name__ == "__main__":
    cli()
